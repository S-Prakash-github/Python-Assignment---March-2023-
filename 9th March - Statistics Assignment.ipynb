{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d29a5c0",
   "metadata": {},
   "source": [
    "#### Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4321c3",
   "metadata": {},
   "source": [
    "The PMF is used to describe the probability distribution of a discrete random variable. A discrete random variable is a variable that can take on only a finite or countably infinite set of distinct values. The PMF assigns a probability to each possible value of the random variable, and the sum of all probabilities equals 1.\n",
    "Suppose we have a random variable X that represents the outcome of a fair six-sided die roll. X can take on the values 1, 2, 3, 4, 5, and 6, each with probability 1/6. This is an example of a discrete random variable.\n",
    "\n",
    "The PMF of X is given by:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df51c1",
   "metadata": {},
   "source": [
    "P(X = 1) = 1/6\n",
    "P(X = 2) = 1/6\n",
    "P(X = 3) = 1/6\n",
    "P(X = 4) = 1/6\n",
    "P(X = 5) = 1/6\n",
    "P(X = 6) = 1/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28322267",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for pmf\n",
    "def pmf(X, x_values):\n",
    "    \"\"\"\n",
    "    Calculate the Probability Mass Function (PMF) of a discrete random variable X at a given set of values.\n",
    "    \"\"\"\n",
    "    pmf_values = []\n",
    "    for x in x_values:\n",
    "        pmf_values.append(X.count(x) / len(X))\n",
    "    return pmf_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc22f5cd",
   "metadata": {},
   "source": [
    "Note that the sum of all probabilities equals 1.\n",
    "\n",
    "Now suppose we have a random variable Y that represents the height of a randomly selected person in a certain population. Y can take on any value within a certain range, say from 4 feet to 7 feet. This is an example of a continuous random variable.\n",
    "\n",
    "The PDF of Y can be any function that satisfies the following conditions:\n",
    "\n",
    "The PDF is always non-negative.\n",
    "The area under the PDF curve within the range of values of Y is equal to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a90eeeb",
   "metadata": {},
   "source": [
    "One example of a PDF for Y is the normal distribution with mean 5.5 feet and standard deviation 0.5 feet:\n",
    "\n",
    "scss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9348885",
   "metadata": {},
   "source": [
    "f(y) = (1 / (0.5 * sqrt(2*pi))) * exp(-((y - 5.5)**2) / (2 * (0.5**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51b702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def pdf(x, mu, sigma):\n",
    "    \"\"\"\n",
    "    Calculate the Probability Density Function (PDF) of a normal distribution with mean mu and standard deviation sigma\n",
    "    at a given point x.\n",
    "    \"\"\"\n",
    "    return (1 / (sigma * math.sqrt(2*math.pi))) * math.exp(-((x - mu)**2) / (2 * (sigma**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48e450f",
   "metadata": {},
   "source": [
    "This PDF assigns a higher probability density to heights close to the mean of 5.5 feet and a lower probability density to heights further away from the mean.\n",
    "\n",
    "In summary, the PMF and PDF are probability distribution functions used to describe the probability distribution of discrete and continuous random variables, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160ddb5",
   "metadata": {},
   "source": [
    "#### Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed41df79",
   "metadata": {},
   "source": [
    "The Cumulative Density Function (CDF) is a function used in probability theory and statistics to describe the probability distribution of a random variable. The CDF gives the probability that the value of the random variable is less than or equal to a certain value.\n",
    "\n",
    "For a discrete random variable, the CDF is defined as the sum of the probabilities of all values less than or equal to the given value. For a continuous random variable, the CDF is defined as the integral of the PDF from negative infinity up to the given value.\n",
    "\n",
    "The CDF is useful in many statistical applications, such as hypothesis testing and confidence interval estimation. It allows us to calculate probabilities for a range of values of a random variable, and to compare different probability distributions.\n",
    "\n",
    "Here's an example to illustrate the CDF:\n",
    "\n",
    "Suppose we have a random variable X that represents the number of heads obtained in two coin flips. X can take on the values 0, 1, or 2, each with probability 1/4. This is an example of a discrete random variable.\n",
    "\n",
    "The CDF of X is given by:\n",
    "\n",
    "\n",
    ">F(x) = P(X <= x)\n",
    "\n",
    " >For x < 0: F(x) = 0\n",
    " \n",
    " >For 0 <= x < 1: F(x) = 1/4\n",
    " \n",
    " >For 1 <= x < 2: F(x) = 3/4\n",
    " \n",
    " >For x >= 2: F(x) = 1\n",
    "\n",
    "The CDF is a step function that increases in discrete jumps at the possible values of the random variable. For example, F(0) = 1/4, F(1) = 3/4, and F(2) = 1.\n",
    "\n",
    "We can use the CDF to calculate probabilities for a range of values of X. For example, the probability of getting at most one head in two coin flips is:\n",
    "\n",
    "\n",
    "P(X <= 1) = F(1) = 3/4\n",
    "In summary, the CDF is a function used to describe the probability distribution of a random variable. It gives the probability that the value of the random variable is less than or equal to a certain value. The CDF is useful in many statistical applications, and allows us to calculate probabilities for a range of values of a random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91194268",
   "metadata": {},
   "source": [
    "#### Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e290b2f",
   "metadata": {},
   "source": [
    "The normal distribution is one of the most widely used probability distributions in statistics and has a wide range of applications. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "- Height and weight measurements: In many populations, the distribution of heights and weights follows a normal distribution.\n",
    "\n",
    "- IQ scores: Intelligence quotient (IQ) scores are often modeled using a normal distribution.\n",
    "\n",
    "- Errors in measurement: In many scientific experiments, measurements contain random error that is normally distributed.\n",
    "\n",
    "- Financial markets: The daily returns of stocks and other financial assets are often assumed to follow a normal distribution.\n",
    "\n",
    "The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean represents the center of the distribution, while the standard deviation represents the spread of the distribution. The shape of the normal distribution is symmetric and bell-shaped, with the peak of the curve at the mean.\n",
    "\n",
    "The standard deviation determines the width of the bell curve. A smaller standard deviation produces a narrower bell curve, while a larger standard deviation produces a wider bell curve. The mean determines the center of the distribution, so if the mean is shifted to the right, the entire distribution will shift to the right. Conversely, if the mean is shifted to the left, the entire distribution will shift to the left."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af095b39",
   "metadata": {},
   "source": [
    "#### Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b111099",
   "metadata": {},
   "source": [
    "The normal distribution is an important statistical concept with wide-ranging applications in various fields. Some key reasons why normal distribution is important are:\n",
    "\n",
    "- Common occurrence: Many natural and human-made phenomena follow a normal distribution, which makes it a useful tool for modeling and understanding the world around us.\n",
    "\n",
    "- Central Limit Theorem: The normal distribution is central to the Central Limit Theorem, which states that the sum or average of a large number of independent and identically distributed random variables tends to be normally distributed, even if the original variables themselves are not normally distributed. This theorem underpins many statistical analyses and inference procedures.\n",
    "\n",
    "- Statistical inference: The normal distribution is widely used in statistical inference, such as hypothesis testing and confidence interval estimation. This is because many test statistics have normal distributions under certain assumptions, which allows us to make probabilistic statements about the population parameters of interest.\n",
    "\n",
    "Some real-life examples of normal distribution are:\n",
    "\n",
    ">Heights of people: The distribution of heights in many populations follows a normal distribution, with the mean height being around the center of the distribution.\n",
    "\n",
    ">IQ scores: Intelligence quotient (IQ) scores are often modeled using a normal distribution, with the mean being set at 100 and the standard deviation at 15.\n",
    "\n",
    ">Exam scores: In many educational settings, exam scores tend to follow a normal distribution, with the mean and standard deviation reflecting the difficulty of the exam.\n",
    "\n",
    ">Financial markets: The daily returns of stocks and other financial assets are often assumed to follow a normal distribution, with the mean reflecting the average rate of return and the standard deviation reflecting the volatility of the asset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be2b3d",
   "metadata": {},
   "source": [
    "#### Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bca9a1e",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models the outcome of a single binary experiment, where there are only two possible outcomes: success (1) or failure (0). The Bernoulli distribution is named after Swiss mathematician Jacob Bernoulli, who introduced the concept in the early 18th century.\n",
    "\n",
    "An example of the Bernoulli distribution is flipping a fair coin, where the outcome is either heads (success) or tails (failure). Another example is rolling a die and considering a success to be rolling a six.\n",
    "\n",
    "The Bernoulli distribution is a special case of the binomial distribution, which models the number of successes in a fixed number of independent Bernoulli trials. The key difference between the Bernoulli and binomial distributions is that the Bernoulli distribution models a single trial, while the binomial distribution models multiple trials.\n",
    "\n",
    "In the Bernoulli distribution, there is only one parameter, which is the probability of success (denoted by p). In the binomial distribution, there are two parameters: the number of trials (n) and the probability of success (p).\n",
    "\n",
    "For example, suppose we flip a fair coin 10 times and count the number of heads. The number of heads is a random variable that follows a binomial distribution with parameters n=10 and p=0.5. The probability of getting exactly k heads (where k can be any integer from 0 to 10) is given by the binomial probability mass function.\n",
    "\n",
    "In summary, the Bernoulli distribution models the outcome of a single binary experiment, while the binomial distribution models the number of successes in a fixed number of independent Bernoulli trials. The Bernoulli distribution is a special case of the binomial distribution, with n=1.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb20fa6",
   "metadata": {},
   "source": [
    "#### Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba3c5a7",
   "metadata": {},
   "source": [
    "To find the probability that a randomly selected observation will be greater than 60 from a normally distributed dataset with mean μ = 50 and standard deviation σ = 10, we need to standardize the value of 60 using the z-score formula:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where x is the observed value, μ is the mean, and σ is the standard deviation.\n",
    "\n",
    "Substituting the values, we get:\n",
    "\n",
    "z = (60 - 50) / 10 = 1\n",
    "\n",
    "Now, we need to find the area under the standard normal distribution curve to the right of z = 1, which represents the probability of getting a value greater than 60. We can use a z-table or a calculator to find this area, which is approximately 0.1587.\n",
    "\n",
    "Therefore, the probability of a randomly selected observation being greater than 60 is 0.1587 or 15.87%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29014045",
   "metadata": {},
   "source": [
    "#### Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e4ad10",
   "metadata": {},
   "source": [
    "The uniform distribution is a continuous probability distribution that models a situation where any value within a given range is equally likely to occur. In other words, the probability density function of the uniform distribution is a constant over a specified range.\n",
    "\n",
    "An example of the uniform distribution is rolling a fair die, where each of the six outcomes (1, 2, 3, 4, 5, or 6) is equally likely to occur. The probability of each outcome is 1/6, which is a constant value over the range of possible outcomes.\n",
    "\n",
    "Another example is choosing a random number between 0 and 1. Since any value between 0 and 1 is equally likely to be chosen, the probability density function of this distribution is a horizontal line with a height of 1 over the range [0, 1].\n",
    "\n",
    "In general, the uniform distribution is useful for modeling situations where there is no preference or bias for any particular value within a given range. It is often used in simulations and modeling, as well as in statistical inference and hypothesis testing.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b1375a",
   "metadata": {},
   "source": [
    "#### Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf5643",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score, is a dimensionless quantity that represents the number of standard deviations an observation or data point is from the mean of a distribution. The z-score is calculated as:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where x is the observed value, μ is the mean of the distribution, and σ is the standard deviation of the distribution.\n",
    "\n",
    "The z-score allows us to standardize observations from different normal distributions, making it possible to compare them on a common scale. The z-score can be positive, negative, or zero, depending on whether the observed value is above, below, or equal to the mean of the distribution.\n",
    "\n",
    "The importance of the z-score lies in its usefulness in statistical analysis, particularly in hypothesis testing and confidence intervals. By converting observations to z-scores, we can calculate the probability of observing a value as extreme or more extreme than the observed value, assuming a normal distribution. This probability can be used to make inferences about the population from which the sample was drawn.\n",
    "\n",
    "The z-score is also used in quality control to identify outliers, which are observations that are more than a certain number of standard deviations away from the mean. Outliers can indicate problems in the data collection process or suggest the presence of unusual or unexpected phenomena."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9973507e",
   "metadata": {},
   "source": [
    "#### Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf75b9b0",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental theorem in statistics that describes the behavior of the sample mean of a random variable as the sample size increases, regardless of the underlying distribution. The CLT states that, under certain conditions, the distribution of sample means approximates a normal distribution, regardless of the shape of the population distribution.\n",
    "\n",
    "In more formal terms, the CLT states that as the sample size n increases, the distribution of the sample mean X̄ approaches a normal distribution with mean μ and standard deviation σ/√n, where μ and σ are the mean and standard deviation of the population, respectively.\n",
    "\n",
    "The significance of the CLT lies in its usefulness in statistical inference. It allows us to make inferences about a population from a sample, even if the population distribution is unknown or non-normal. By taking multiple samples and calculating their means, we can approximate the population mean and standard deviation and make inferences about the population.\n",
    "\n",
    "The CLT also has practical applications in many areas of science, engineering, and finance. For example, it is commonly used in quality control to monitor the quality of a product by taking multiple samples and analyzing the means, in finance to model the behavior of stock prices and returns, and in physics to model the behavior of particles in a gas or liquid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17afce1f",
   "metadata": {},
   "source": [
    "#### Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d8cfb5",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is based on certain assumptions that must be satisfied for the theorem to hold true. The assumptions of the CLT are:\n",
    "\n",
    ">Independence: The observations in the sample must be independent of each other.\n",
    "\n",
    ">Sample size: The sample size n must be sufficiently large. The general rule of thumb is that the sample size should be greater than or equal to 30. However, if the population is highly skewed or has heavy tails, a larger sample size may be required.\n",
    "\n",
    ">Identical distribution: The observations in the sample must be drawn from the same population distribution.\n",
    "\n",
    ">Finite variance: The population from which the sample is drawn must have a finite variance.\n",
    "\n",
    ">Randomness: The sample must be selected at random from the population.\n",
    "\n",
    "If these assumptions are met, then the sample means will follow a normal distribution as the sample size increases. The CLT is a powerful tool that allows us to make statistical inferences about a population, but it is important to ensure that the assumptions are satisfied before relying on the theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d704887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9ead6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
